# Snek_AI
Video Link: https://youtu.be/SKw1DESS3IA 

Write Up, Group: Thomas Kummer, Willem Shak

The project we were trying to solve in this project was to create an AI model that learns to play the simple game Snake, or more generally to train an agent to do well in an environment.  This may seem like a small game with no other applications, but creating an agent that can learn to act efficiently in an environment very useful when more complicated.  It can be used in games to train AI to walk like real people or a cool application may be in an amazon warehouse, where we try to maximize package throughput with robots. The robots could be trained using a genetic algorithm in a simulated environment where they are rewarded for throughput, and eventually they can collectively have great throughput when they path optimally and work together.

The source of data for this project was our own.  We created a snake game that draws the snake and a random food location and then moves the snake in the inputed direction until a collision with itself or the wall occurs.  Colliding with the food also makes the snake grow and randomly places another food.  The snake and its environment(board) was the source of our data that was fed to the neural network, who's weights were initially random. As generations were created, the best performer's neural networks were then used to construct the new generation's neural networks.

We were able to create an agent that ate 10 food before dying, which is certainly not coincidental, as when we ran it individually it had consistent performance. It was able to go in the direction of the food and eat it, while its pathing was not optimal. It had a quirk where it liked to go to the left wall before eating the next food, likely due to some random left-wall enjoying snake performing really well. The snake also seemed to avoid walls and its own body relatively well, so it was able to learn that crashing was a negative action. It exhibited very basic understandings of its purpose; eating food, and not dying, however it did not develop any advanced behaviors. By advanced behaviors I mean that it isn't able to reach a high score, or plan decently ahead to not trap itself, or path efficiently to food.

If we were to continue with his project, the end goal would be for our snake to be able to occupy the entire board, winning the game, exhibiting these advanced behaviors. Several areas for improvement are the rates at which I breed and mutate the snakes, and maybe our input data is not comprehensive enough. Tweaking the mutation and breeding could produce more favorable snakes, which converge to a better snake population faster, or at all. The input data could definitely be changed, as just knowing the food direction, snake direction, and blocks directly near the snake's head is not enough to play a full game of snake. However, it is enough to get a basic understanding of the game.  For it to win the game, it would have to be mindful of its entire body, ensuring it won't trap itself. If we inputed an entire game state the snake would be able to learn much quicker on the best way to reach the food, however this would take a lot more processing power and intern would cause the snakes to run much slower and each generation would take exponentially longer than it does now.  Finding a middle ground between the data we've inputed and the entire board would take a while, but it could greatly improve the speed at which the AI learns to play the game. I could also change the structure of the neural network, as maybe 7, 9, 15, 3 was not suitable for this case. I would also have to investigate the reasoning for certain structures of neural networks, as 7 9 15 3 was just an arbitrary count, without much reasoning. Maybe the number of nodes could be optimized for this snake situation.

The best thing we've learned from this experiment is how neural networks and genetic algorithms work together due to us implementing them by hand rather than using a library.  Our neural network outputs a direction based on the input variables, and the neural networks are combined and mutated to converge on a better performing snake.  Our genetic algorithm finds the best performers from each generation and breeds them together to hopefully get the best traits from each.  This allows our best performers to mutate by combining with one another, and then taking the best of those mutations to combine with one another.  We didn't split up the work and instead opted to code together.  Since one of us was on the West Coast and the other the East Coast we created calls and one of us would share our screen and code while the other would assist.  This lead to us both completing a majority of the project and helping the other through bugs and errors.
